{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#INSTALADORES"
      ],
      "metadata": {
        "id": "_kiCqVZRcZhm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4aDm5TNRY5eY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d69004-96c9-40aa-ad88-c760e18eadb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard\n",
        "!pip install torchinfo\n",
        "!pip install --upgrade torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZYW89iJfzrac",
        "outputId": "4b5d5d68-0ee1-4471-aab0-998153772baf"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.1+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "r9ok5rZZcgqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu3FLT0dTXk0",
        "outputId": "ee076001-c15f-4f93-8397-de249de561d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp \"/content/drive/MyDrive/Colab Notebooks/MLP/data.csv\" /content\n",
        "! cp \"/content/drive/MyDrive/Colab Notebooks/MLP/img.zip\" /content\n",
        "! unzip -q img.zip\n",
        "! rm img.zip"
      ],
      "metadata": {
        "id": "06svX9WspPhm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Weights and Biases INICIALIZACION"
      ],
      "metadata": {
        "id": "fOBI94ROcO25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "\n",
        "FALTA GENERAR EL PROYECTO MLP-Obligatorio  Y  OBTENER CLAVE\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "BVIaUD7HPXBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FUNCIONES BASE ENTRENO"
      ],
      "metadata": {
        "id": "0ApXh6VQc_tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchinfo\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import csv\n",
        "from PIL import Image\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "hPA9TFLZZoIh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_oneHot(label, numberOfClass):\n",
        "  oneHot_label = torch.zeros(label.shape[0],numberOfClass).to(device)\n",
        "  for i in range(label.shape[0]):\n",
        "    oneHot_label[i][label[i]]=1\n",
        "  return oneHot_label\n",
        "\n",
        "def train_step(mlp_model, criterion, optim, img,tabulars, label, batch_size, numberOfClass):\n",
        "    optim.zero_grad()\n",
        "    output = mlp_model(img, tabulars)\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    step_loss = loss.item()\n",
        "    return step_loss\n",
        "\n",
        "def train_epoch(mlp_model, loader, criterion, optim,mb,numberOfClass):\n",
        "    epoch_loss_accumulated = 0.0\n",
        "    for img, tabulars, labels in  progress_bar(loader,parent = mb):\n",
        "      batch_size = img.size(0)\n",
        "      epoch_loss_accumulated += train_step(mlp_model,criterion,optim, img.to(device), tabulars.to(device), labels.to(device), batch_size,numberOfClass)\n",
        "    return epoch_loss_accumulated/len(loader)"
      ],
      "metadata": {
        "id": "eLuLVq3YA1rQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_epoch(mlp_model, val_loader, criterion, classes = None):\n",
        "    mlp_model.eval()\n",
        "    epoch_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for images, tabulars, labels in val_loader:\n",
        "        all_labels.extend(torch.argmax(labels, dim=1).cpu().numpy())\n",
        "        tabulars = tabulars.to(device)\n",
        "        labels = labels.to(device)\n",
        "        predictions = mlp_model(images.to(device), tabulars)\n",
        "        all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(val_loader), accuracy_score(all_labels, all_predictions) * 100"
      ],
      "metadata": {
        "id": "kjRB0qPKypTK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(mlp_model, train_loader, valid_loader, criterion, optim, number_epochs,numberOfClass):\n",
        "  train_history = []\n",
        "  valid_history = []\n",
        "  accuracy_history = []\n",
        "  now = datetime.datetime.now()\n",
        "  date_time = now.strftime(\"%m%d%Y_%H%M%S\")\n",
        "  name = 'runs/'+mlp_model.name+'_'+date_time\n",
        "  tensorBoard_writer = SummaryWriter(name)\n",
        "  mb = master_bar(range(1, number_epochs+1))\n",
        "  for epoch in mb:\n",
        "      start_time = time.time()\n",
        "      train_loss = train_epoch(mlp_model, train_loader, criterion, optim,mb,numberOfClass)\n",
        "      train_history.append(train_loss)\n",
        "      print(\"Training epoch {} | Loss {:.6f} | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, train_loss, time.time() - start_time))\n",
        "\n",
        "      start_time = time.time()\n",
        "      val_loss, acc = validation_epoch(mlp_model, valid_loader, criterion)\n",
        "      valid_history.append(val_loss)\n",
        "      accuracy_history.append(acc)\n",
        "      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, val_loss, acc, time.time() - start_time))\n",
        "      # Se carga en tensorBoard #Loss #Validation en train y val\n",
        "      tensorBoard_writer.add_scalar(tag=\"Train Loss\", scalar_value=train_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Loss\", scalar_value=val_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Accuracy\", scalar_value=acc, global_step=epoch)\n",
        "  tensorBoard_writer.close()"
      ],
      "metadata": {
        "id": "o2Q_Vlm0UYK7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CARGA DE DATOS"
      ],
      "metadata": {
        "id": "oNQ0ZMJFCxUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  data = []\n",
        "  with open(\"./data.csv\", 'r') as file:\n",
        "    lector_csv = csv.reader(file)\n",
        "    next(lector_csv)\n",
        "    for fila in lector_csv:\n",
        "      fila_enteros = [int(float(valor)) for valor in fila]\n",
        "      data.append(fila_enteros)\n",
        "\n",
        "  data = np.array(data)\n",
        "  nombres_imagenes = data[:, 0]\n",
        "\n",
        "  datos_con_imagenes = []\n",
        "\n",
        "  for nombre_imagen, fila_datos in zip(nombres_imagenes, data):\n",
        "      imagen = 0\n",
        "      try:\n",
        "        imagen = Image.open(\"./img/\" + str(nombre_imagen))\n",
        "        label = [1,0,0,0]\n",
        "        if fila_datos[6] > 100000 and fila_datos[6] <= 200000:\n",
        "          label = [0,1,0,0]\n",
        "        elif fila_datos[6] > 200000 and fila_datos[6] <= 300000:\n",
        "          label = [0,0,1,0]\n",
        "        elif fila_datos[6] > 300000:\n",
        "          label = [0,0,0,1]\n",
        "        imagen = np.array(imagen)\n",
        "        label = (np.array(label)).astype(float)\n",
        "        datos_con_imagenes.append([imagen, fila_datos[1:6], label])\n",
        "      except FileNotFoundError:\n",
        "        print(\"Error: El archivo de imagen \" + str(nombre_imagen)+ \".jpeg no existe.\")\n",
        "\n",
        "  print(len(datos_con_imagenes))\n",
        "  return datos_con_imagenes"
      ],
      "metadata": {
        "id": "BH7li8FJv61n"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(train_transf,batch_size):\n",
        "# Vector de vectores img, tabulares, label -------------------------------------------------------------------------------------------------------------------------------------\n",
        "  train_dataset = load_data()\n",
        "# Vector de vectores img, tabulares, label -------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  BATCH_SIZE = batch_size\n",
        "\n",
        "  # Separamos en train y validation\n",
        "  train_size = int(0.8 * len(train_dataset))\n",
        "  valid_size = len(train_dataset) - train_size\n",
        "\n",
        "  train, validation = torch.utils.data.random_split(train_dataset, [train_size,valid_size])\n",
        "\n",
        "  print(f\"{len(train)} Training Items, {len(validation)} Validation Items\")\n",
        "\n",
        "  # Podemos usar data loaders como vimos en el práctico.\n",
        "  train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True,pin_memory=True)\n",
        "  valid_loader = DataLoader(validation, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "\n",
        "  return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "jqO-VeKccgRg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODELO"
      ],
      "metadata": {
        "id": "-Ww-iF4vDILl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "DTVLeMkfHqji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8249096-571f-48c1-d776-ba1944feebdd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_Model(nn.Module):\n",
        "  def __init__(self,name=\"MLP_MODEL\", vocab_size=260, embedding_dim=4, num_classes=4):\n",
        "    super().__init__()\n",
        "    self.name = name\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim)\n",
        "    self.conv1 = nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(256)\n",
        "    self.conv4 = nn.Conv2d(256, 64, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn4 = nn.BatchNorm2d(64)\n",
        "    self.linear1 = nn.Linear(64*16*12+5+(embedding_dim-1), 1024)\n",
        "    self.linear2 = nn.Linear(1024, 512)\n",
        "    self.linear3 = nn.Linear(512, 128)\n",
        "    self.linear4 = nn.Linear(128, 64)\n",
        "    self.out = nn.Linear(64, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x,tabulars):\n",
        "    # entrada de 256*192\n",
        "    emb_Location = self.embedding(tabulars[:,4])\n",
        "    #plt.imshow(x[0])\n",
        "    x = x.view(x.size(0), 3, 256, 192)\n",
        "    x = torch.round(x).to(torch.float32)\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    x = F.relu(self.bn4(self.conv4(x)))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = torch.concat([x, tabulars[:,0:4], emb_Location], -1)\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = F.relu(self.linear2(x))\n",
        "    x = F.relu(self.linear3(x))\n",
        "    x = F.relu(self.linear4(x))\n",
        "    x = torch.sigmoid(self.out(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "Vjr6zGNfWcwb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchinfo.summary(MLP_Model())"
      ],
      "metadata": {
        "id": "hp9pNKPObREb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed6851a-007e-4114-b124-82bb11ec0284"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=================================================================\n",
              "Layer (type:depth-idx)                   Param #\n",
              "=================================================================\n",
              "MLP_Model                                --\n",
              "├─Embedding: 1-1                         1,040\n",
              "├─Conv2d: 1-2                            3,072\n",
              "├─BatchNorm2d: 1-3                       128\n",
              "├─Conv2d: 1-4                            131,072\n",
              "├─BatchNorm2d: 1-5                       256\n",
              "├─Conv2d: 1-6                            524,288\n",
              "├─BatchNorm2d: 1-7                       512\n",
              "├─Conv2d: 1-8                            262,144\n",
              "├─BatchNorm2d: 1-9                       128\n",
              "├─Linear: 1-10                           12,592,128\n",
              "├─Linear: 1-11                           524,800\n",
              "├─Linear: 1-12                           65,664\n",
              "├─Linear: 1-13                           8,256\n",
              "├─Linear: 1-14                           260\n",
              "=================================================================\n",
              "Total params: 14,113,748\n",
              "Trainable params: 14,113,748\n",
              "Non-trainable params: 0\n",
              "================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PARAMETROS"
      ],
      "metadata": {
        "id": "46EeU_3DDUav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb.config # Config is a variable that holds and saves hyperparameters and inputs\n",
        "\n",
        "config.LR = 2e-4\n",
        "config.epochs = 50\n",
        "config.batch_size = 32\n",
        "config.B = [0.5,0.999]\n",
        "config.info = 'Modelo MLP'"
      ],
      "metadata": {
        "id": "J3Ru6ebWQ0JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo y el optimizador\n",
        "LR = 0.01\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "B = [0.5,0.999]"
      ],
      "metadata": {
        "id": "3GeuvA4gYlnh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "joJAzx9jDY5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos los dataloaders\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize([256,192]),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Creamos el loaders\n",
        "train_loader, val_loader = get_dataloaders(train_transform,batch_size)"
      ],
      "metadata": {
        "id": "fLVRgXZ9wZNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5b76cdc-1e75-4306-9f54-7f6732590b90"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: El archivo de imagen 1787.jpeg no existe.\n",
            "Error: El archivo de imagen 1942.jpeg no existe.\n",
            "Error: El archivo de imagen 3140.jpeg no existe.\n",
            "Error: El archivo de imagen 3280.jpeg no existe.\n",
            "Error: El archivo de imagen 3297.jpeg no existe.\n",
            "Error: El archivo de imagen 3308.jpeg no existe.\n",
            "Error: El archivo de imagen 3667.jpeg no existe.\n",
            "Error: El archivo de imagen 3720.jpeg no existe.\n",
            "Error: El archivo de imagen 3784.jpeg no existe.\n",
            "Error: El archivo de imagen 4348.jpeg no existe.\n",
            "Error: El archivo de imagen 4621.jpeg no existe.\n",
            "Error: El archivo de imagen 5423.jpeg no existe.\n",
            "Error: El archivo de imagen 5492.jpeg no existe.\n",
            "Error: El archivo de imagen 5900.jpeg no existe.\n",
            "Error: El archivo de imagen 5918.jpeg no existe.\n",
            "Error: El archivo de imagen 6018.jpeg no existe.\n",
            "Error: El archivo de imagen 6071.jpeg no existe.\n",
            "Error: El archivo de imagen 7318.jpeg no existe.\n",
            "Error: El archivo de imagen 7701.jpeg no existe.\n",
            "Error: El archivo de imagen 7769.jpeg no existe.\n",
            "Error: El archivo de imagen 8312.jpeg no existe.\n",
            "Error: El archivo de imagen 8501.jpeg no existe.\n",
            "Error: El archivo de imagen 8650.jpeg no existe.\n",
            "Error: El archivo de imagen 8788.jpeg no existe.\n",
            "Error: El archivo de imagen 8821.jpeg no existe.\n",
            "Error: El archivo de imagen 8917.jpeg no existe.\n",
            "Error: El archivo de imagen 9450.jpeg no existe.\n",
            "Error: El archivo de imagen 10340.jpeg no existe.\n",
            "Error: El archivo de imagen 11178.jpeg no existe.\n",
            "Error: El archivo de imagen 11243.jpeg no existe.\n",
            "Error: El archivo de imagen 11614.jpeg no existe.\n",
            "Error: El archivo de imagen 11781.jpeg no existe.\n",
            "Error: El archivo de imagen 11830.jpeg no existe.\n",
            "Error: El archivo de imagen 13931.jpeg no existe.\n",
            "Error: El archivo de imagen 14094.jpeg no existe.\n",
            "Error: El archivo de imagen 14524.jpeg no existe.\n",
            "Error: El archivo de imagen 14706.jpeg no existe.\n",
            "Error: El archivo de imagen 15320.jpeg no existe.\n",
            "Error: El archivo de imagen 15814.jpeg no existe.\n",
            "Error: El archivo de imagen 16742.jpeg no existe.\n",
            "Error: El archivo de imagen 16747.jpeg no existe.\n",
            "Error: El archivo de imagen 16887.jpeg no existe.\n",
            "Error: El archivo de imagen 16918.jpeg no existe.\n",
            "Error: El archivo de imagen 16935.jpeg no existe.\n",
            "Error: El archivo de imagen 17097.jpeg no existe.\n",
            "Error: El archivo de imagen 17441.jpeg no existe.\n",
            "Error: El archivo de imagen 18949.jpeg no existe.\n",
            "Error: El archivo de imagen 19216.jpeg no existe.\n",
            "Error: El archivo de imagen 19638.jpeg no existe.\n",
            "Error: El archivo de imagen 19959.jpeg no existe.\n",
            "Error: El archivo de imagen 20058.jpeg no existe.\n",
            "Error: El archivo de imagen 20129.jpeg no existe.\n",
            "Error: El archivo de imagen 20159.jpeg no existe.\n",
            "Error: El archivo de imagen 20544.jpeg no existe.\n",
            "Error: El archivo de imagen 20679.jpeg no existe.\n",
            "Error: El archivo de imagen 21108.jpeg no existe.\n",
            "Error: El archivo de imagen 22079.jpeg no existe.\n",
            "Error: El archivo de imagen 22244.jpeg no existe.\n",
            "Error: El archivo de imagen 22272.jpeg no existe.\n",
            "Error: El archivo de imagen 22619.jpeg no existe.\n",
            "Error: El archivo de imagen 22830.jpeg no existe.\n",
            "Error: El archivo de imagen 23190.jpeg no existe.\n",
            "Error: El archivo de imagen 23277.jpeg no existe.\n",
            "Error: El archivo de imagen 23575.jpeg no existe.\n",
            "Error: El archivo de imagen 24091.jpeg no existe.\n",
            "Error: El archivo de imagen 24735.jpeg no existe.\n",
            "Error: El archivo de imagen 25128.jpeg no existe.\n",
            "Error: El archivo de imagen 25761.jpeg no existe.\n",
            "Error: El archivo de imagen 26000.jpeg no existe.\n",
            "Error: El archivo de imagen 26248.jpeg no existe.\n",
            "Error: El archivo de imagen 26743.jpeg no existe.\n",
            "Error: El archivo de imagen 26854.jpeg no existe.\n",
            "Error: El archivo de imagen 27635.jpeg no existe.\n",
            "Error: El archivo de imagen 29371.jpeg no existe.\n",
            "Error: El archivo de imagen 29473.jpeg no existe.\n",
            "Error: El archivo de imagen 29820.jpeg no existe.\n",
            "Error: El archivo de imagen 30147.jpeg no existe.\n",
            "Error: El archivo de imagen 30532.jpeg no existe.\n",
            "Error: El archivo de imagen 31241.jpeg no existe.\n",
            "Error: El archivo de imagen 31854.jpeg no existe.\n",
            "Error: El archivo de imagen 32065.jpeg no existe.\n",
            "Error: El archivo de imagen 32458.jpeg no existe.\n",
            "Error: El archivo de imagen 32876.jpeg no existe.\n",
            "Error: El archivo de imagen 33089.jpeg no existe.\n",
            "Error: El archivo de imagen 33363.jpeg no existe.\n",
            "Error: El archivo de imagen 34188.jpeg no existe.\n",
            "Error: El archivo de imagen 34281.jpeg no existe.\n",
            "Error: El archivo de imagen 34785.jpeg no existe.\n",
            "Error: El archivo de imagen 34856.jpeg no existe.\n",
            "Error: El archivo de imagen 35378.jpeg no existe.\n",
            "Error: El archivo de imagen 36769.jpeg no existe.\n",
            "Error: El archivo de imagen 36801.jpeg no existe.\n",
            "Error: El archivo de imagen 37702.jpeg no existe.\n",
            "Error: El archivo de imagen 38168.jpeg no existe.\n",
            "Error: El archivo de imagen 38855.jpeg no existe.\n",
            "Error: El archivo de imagen 38990.jpeg no existe.\n",
            "Error: El archivo de imagen 39594.jpeg no existe.\n",
            "Error: El archivo de imagen 39843.jpeg no existe.\n",
            "Error: El archivo de imagen 39944.jpeg no existe.\n",
            "Error: El archivo de imagen 39996.jpeg no existe.\n",
            "Error: El archivo de imagen 40099.jpeg no existe.\n",
            "Error: El archivo de imagen 41026.jpeg no existe.\n",
            "Error: El archivo de imagen 41087.jpeg no existe.\n",
            "Error: El archivo de imagen 41630.jpeg no existe.\n",
            "Error: El archivo de imagen 42443.jpeg no existe.\n",
            "Error: El archivo de imagen 42977.jpeg no existe.\n",
            "Error: El archivo de imagen 43082.jpeg no existe.\n",
            "Error: El archivo de imagen 43177.jpeg no existe.\n",
            "Error: El archivo de imagen 43580.jpeg no existe.\n",
            "Error: El archivo de imagen 43795.jpeg no existe.\n",
            "Error: El archivo de imagen 44808.jpeg no existe.\n",
            "Error: El archivo de imagen 44923.jpeg no existe.\n",
            "Error: El archivo de imagen 44990.jpeg no existe.\n",
            "Error: El archivo de imagen 45613.jpeg no existe.\n",
            "Error: El archivo de imagen 45764.jpeg no existe.\n",
            "Error: El archivo de imagen 47459.jpeg no existe.\n",
            "Error: El archivo de imagen 47462.jpeg no existe.\n",
            "Error: El archivo de imagen 47759.jpeg no existe.\n",
            "Error: El archivo de imagen 48103.jpeg no existe.\n",
            "Error: El archivo de imagen 48289.jpeg no existe.\n",
            "Error: El archivo de imagen 48517.jpeg no existe.\n",
            "Error: El archivo de imagen 48870.jpeg no existe.\n",
            "24977\n",
            "19981 Training Items, 4996 Validation Items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = MLP_Model(\"MLP MODEL\", vocab_size=260, embedding_dim=4, num_classes=4).to(device)\n",
        "opt = torch.optim.Adam(mlp_model.parameters(), lr=LR,betas=B)\n",
        "crit = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "pSliMcSa2m6G"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(mlp_model, train_loader, val_loader, crit, opt, epochs, 4)"
      ],
      "metadata": {
        "id": "1qMpWzA5_lSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "785ff013-1b1b-403b-fbb6-e9533bbefa06"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch 2 | Loss 1.082640 | Time 44.67 seconds\n",
            "Validation epoch 2 | Loss 1.049376 | Accuracy 68.45% | Time 3.15 seconds\n",
            "Training epoch 3 | Loss 1.028995 | Time 42.28 seconds\n",
            "Validation epoch 3 | Loss 1.027411 | Accuracy 70.64% | Time 3.16 seconds\n",
            "Training epoch 4 | Loss 1.019332 | Time 42.00 seconds\n",
            "Validation epoch 4 | Loss 1.019096 | Accuracy 71.54% | Time 3.07 seconds\n",
            "Training epoch 5 | Loss 1.013708 | Time 41.60 seconds\n",
            "Validation epoch 5 | Loss 1.009226 | Accuracy 71.88% | Time 3.08 seconds\n",
            "Training epoch 6 | Loss 1.006354 | Time 41.66 seconds\n",
            "Validation epoch 6 | Loss 1.006803 | Accuracy 72.22% | Time 3.04 seconds\n",
            "Training epoch 7 | Loss 1.004093 | Time 41.29 seconds\n",
            "Validation epoch 7 | Loss 1.002372 | Accuracy 72.44% | Time 2.97 seconds\n",
            "Training epoch 8 | Loss 1.000784 | Time 41.33 seconds\n",
            "Validation epoch 8 | Loss 1.000852 | Accuracy 72.80% | Time 3.09 seconds\n",
            "Training epoch 9 | Loss 0.998727 | Time 41.35 seconds\n",
            "Validation epoch 9 | Loss 0.998588 | Accuracy 73.10% | Time 3.12 seconds\n",
            "Training epoch 10 | Loss 0.997926 | Time 41.27 seconds\n",
            "Validation epoch 10 | Loss 0.997406 | Accuracy 73.08% | Time 3.04 seconds\n",
            "Training epoch 11 | Loss 0.993618 | Time 41.16 seconds\n",
            "Validation epoch 11 | Loss 0.994043 | Accuracy 73.78% | Time 3.02 seconds\n",
            "Training epoch 12 | Loss 0.992775 | Time 41.14 seconds\n",
            "Validation epoch 12 | Loss 1.005450 | Accuracy 71.92% | Time 3.00 seconds\n",
            "Training epoch 13 | Loss 0.990201 | Time 41.16 seconds\n",
            "Validation epoch 13 | Loss 0.997015 | Accuracy 73.40% | Time 3.15 seconds\n",
            "Training epoch 14 | Loss 0.987684 | Time 41.42 seconds\n",
            "Validation epoch 14 | Loss 1.003449 | Accuracy 72.36% | Time 3.06 seconds\n",
            "Training epoch 15 | Loss 0.984472 | Time 41.33 seconds\n",
            "Validation epoch 15 | Loss 1.000206 | Accuracy 72.80% | Time 3.04 seconds\n",
            "Training epoch 16 | Loss 0.983783 | Time 41.67 seconds\n",
            "Validation epoch 16 | Loss 0.994393 | Accuracy 73.78% | Time 3.00 seconds\n",
            "Training epoch 17 | Loss 0.982773 | Time 41.40 seconds\n",
            "Validation epoch 17 | Loss 0.993384 | Accuracy 73.32% | Time 3.10 seconds\n",
            "Training epoch 18 | Loss 0.981043 | Time 41.18 seconds\n",
            "Validation epoch 18 | Loss 0.993446 | Accuracy 73.72% | Time 3.00 seconds\n",
            "Training epoch 19 | Loss 0.975568 | Time 41.37 seconds\n",
            "Validation epoch 19 | Loss 0.991038 | Accuracy 74.52% | Time 3.10 seconds\n",
            "Training epoch 20 | Loss 0.978762 | Time 41.43 seconds\n",
            "Validation epoch 20 | Loss 0.991059 | Accuracy 74.38% | Time 3.07 seconds\n",
            "Training epoch 21 | Loss 0.975088 | Time 41.45 seconds\n",
            "Validation epoch 21 | Loss 0.988843 | Accuracy 74.40% | Time 3.17 seconds\n",
            "Training epoch 22 | Loss 0.973774 | Time 41.87 seconds\n",
            "Validation epoch 22 | Loss 0.994951 | Accuracy 73.46% | Time 3.12 seconds\n",
            "Training epoch 23 | Loss 0.973012 | Time 41.34 seconds\n",
            "Validation epoch 23 | Loss 0.994718 | Accuracy 73.52% | Time 3.05 seconds\n",
            "Training epoch 24 | Loss 0.969461 | Time 41.25 seconds\n",
            "Validation epoch 24 | Loss 0.990382 | Accuracy 74.40% | Time 3.03 seconds\n",
            "Training epoch 25 | Loss 0.968715 | Time 41.37 seconds\n",
            "Validation epoch 25 | Loss 0.992559 | Accuracy 74.04% | Time 3.12 seconds\n",
            "Training epoch 26 | Loss 0.969617 | Time 41.36 seconds\n",
            "Validation epoch 26 | Loss 0.996580 | Accuracy 73.52% | Time 3.08 seconds\n",
            "Training epoch 27 | Loss 0.967844 | Time 41.33 seconds\n",
            "Validation epoch 27 | Loss 0.988423 | Accuracy 74.62% | Time 3.03 seconds\n",
            "Training epoch 28 | Loss 0.965971 | Time 41.16 seconds\n",
            "Validation epoch 28 | Loss 0.991573 | Accuracy 74.04% | Time 2.99 seconds\n",
            "Training epoch 29 | Loss 0.963550 | Time 41.14 seconds\n",
            "Validation epoch 29 | Loss 0.991657 | Accuracy 74.32% | Time 3.05 seconds\n",
            "Training epoch 30 | Loss 0.962762 | Time 41.34 seconds\n",
            "Validation epoch 30 | Loss 0.989727 | Accuracy 74.66% | Time 3.13 seconds\n",
            "Training epoch 31 | Loss 0.962814 | Time 41.36 seconds\n",
            "Validation epoch 31 | Loss 0.998322 | Accuracy 73.94% | Time 3.06 seconds\n",
            "Training epoch 32 | Loss 0.962356 | Time 41.60 seconds\n",
            "Validation epoch 32 | Loss 0.992211 | Accuracy 74.10% | Time 3.15 seconds\n",
            "Training epoch 33 | Loss 0.961980 | Time 41.46 seconds\n",
            "Validation epoch 33 | Loss 0.990847 | Accuracy 74.56% | Time 3.15 seconds\n",
            "Training epoch 34 | Loss 0.958516 | Time 41.32 seconds\n",
            "Validation epoch 34 | Loss 0.992396 | Accuracy 73.88% | Time 3.05 seconds\n",
            "Training epoch 35 | Loss 0.959139 | Time 41.39 seconds\n",
            "Validation epoch 35 | Loss 0.995321 | Accuracy 74.16% | Time 3.10 seconds\n",
            "Training epoch 36 | Loss 0.960632 | Time 41.65 seconds\n",
            "Validation epoch 36 | Loss 0.991975 | Accuracy 74.18% | Time 3.11 seconds\n",
            "Training epoch 37 | Loss 0.958687 | Time 41.72 seconds\n",
            "Validation epoch 37 | Loss 0.996206 | Accuracy 73.92% | Time 3.06 seconds\n",
            "Training epoch 38 | Loss 0.958766 | Time 41.29 seconds\n",
            "Validation epoch 38 | Loss 0.990540 | Accuracy 74.28% | Time 3.11 seconds\n",
            "Training epoch 39 | Loss 0.956996 | Time 41.29 seconds\n",
            "Validation epoch 39 | Loss 0.991889 | Accuracy 73.62% | Time 3.02 seconds\n",
            "Training epoch 40 | Loss 0.954225 | Time 41.18 seconds\n",
            "Validation epoch 40 | Loss 0.985115 | Accuracy 74.50% | Time 3.06 seconds\n",
            "Training epoch 41 | Loss 0.952450 | Time 41.33 seconds\n",
            "Validation epoch 41 | Loss 0.991069 | Accuracy 74.62% | Time 3.14 seconds\n",
            "Training epoch 42 | Loss 0.952139 | Time 41.39 seconds\n",
            "Validation epoch 42 | Loss 0.988525 | Accuracy 74.40% | Time 3.08 seconds\n",
            "Training epoch 43 | Loss 0.950597 | Time 41.26 seconds\n",
            "Validation epoch 43 | Loss 0.995061 | Accuracy 74.40% | Time 3.02 seconds\n",
            "Training epoch 44 | Loss 0.952541 | Time 41.26 seconds\n",
            "Validation epoch 44 | Loss 0.986642 | Accuracy 75.06% | Time 3.08 seconds\n",
            "Training epoch 45 | Loss 0.951582 | Time 41.41 seconds\n",
            "Validation epoch 45 | Loss 0.987968 | Accuracy 74.94% | Time 3.15 seconds\n",
            "Training epoch 46 | Loss 0.951980 | Time 41.48 seconds\n",
            "Validation epoch 46 | Loss 1.013163 | Accuracy 72.38% | Time 3.15 seconds\n",
            "Training epoch 47 | Loss 0.949972 | Time 41.50 seconds\n",
            "Validation epoch 47 | Loss 0.986850 | Accuracy 75.02% | Time 3.09 seconds\n",
            "Training epoch 48 | Loss 0.949182 | Time 41.64 seconds\n",
            "Validation epoch 48 | Loss 0.992139 | Accuracy 74.20% | Time 3.12 seconds\n",
            "Training epoch 49 | Loss 0.947858 | Time 41.68 seconds\n",
            "Validation epoch 49 | Loss 0.992290 | Accuracy 74.16% | Time 3.11 seconds\n",
            "Training epoch 50 | Loss 0.951551 | Time 41.55 seconds\n",
            "Validation epoch 50 | Loss 0.988281 | Accuracy 74.50% | Time 3.12 seconds\n",
            "Training epoch 51 | Loss 0.954352 | Time 41.79 seconds\n",
            "Validation epoch 51 | Loss 1.005026 | Accuracy 73.04% | Time 3.11 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardado del modelo\n",
        "\n",
        "torch.save(mlp_model.state_dict(),mlp_model.name+\".dat\")"
      ],
      "metadata": {
        "id": "sU3RPUbglQaM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs/MLP MODEL_06162023_164609"
      ],
      "metadata": {
        "id": "tWTpshes5wYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Weights and Biases IMPLEMENTACION"
      ],
      "metadata": {
        "id": "FqJQhl6pVmlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_2():\n",
        "\n",
        "  train_loader, val_loader, num_classes = get_dataloaders(train_transform,config.batch_size)\n",
        "  mlp_model = MLP_Model(\"MLP MODEL\", vocab_size=200, embedding_dim=4, num_classes=4).to(device)\n",
        "  opt = torch.optim.Adam(mlp_model.parameters(), lr=config.LR,betas=config.B)\n",
        "  crit = nn.CrossEntropyLoss()\n",
        "\n",
        "  train_history = []\n",
        "  valid_history = []\n",
        "  accuracy_history = []\n",
        "  now = datetime.datetime.now()\n",
        "  date_time = now.strftime(\"%m%d%Y_%H%M%S\")\n",
        "  name = 'runs/'+mlp_model.name+'_'+date_time\n",
        "  tensorBoard_writer = SummaryWriter(name)\n",
        "  mb = master_bar(range(1, config.epochs+1))\n",
        "  for epoch in mb:\n",
        "      start_time = time.time()\n",
        "      train_loss = train_epoch(mlp_model, train_loader, crit, opt,mb,num_classes)\n",
        "      train_history.append(train_loss)\n",
        "      print(\"Training epoch {} | Loss {:.6f} | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, train_loss, time.time() - start_time))\n",
        "\n",
        "      start_time = time.time()\n",
        "      val_loss, acc = validation_epoch(mlp_model, val_loader, crit)\n",
        "      valid_history.append(val_loss)\n",
        "      accuracy_history.append(acc)\n",
        "      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, val_loss, acc, time.time() - start_time))\n",
        "      # Se carga en tensorBoard #Loss #Validation en train y val\n",
        "      tensorBoard_writer.add_scalar(tag=\"Train Loss\", scalar_value=train_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Loss\", scalar_value=val_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Accuracy\", scalar_value=acc, global_step=epoch)\n",
        "  tensorBoard_writer.close()"
      ],
      "metadata": {
        "id": "RLWEN2JwXC1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_configuration = {\n",
        "    'method': 'grid',         # 'grid', 'hyperopt', 'bayesian'\n",
        "    'metric': {\n",
        "        'name': 'acc',     # 'accuracy'\n",
        "        'goal': 'maximize'      # 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'batch_size': {'values': [32]},\n",
        "        'epochs': {'values': [5,10,20,50,100]},\n",
        "        'B': {'values': [[0.5,0.999]]},\n",
        "        'learning_rate': {'values': [0.0002, 0.0004, 0.0006, 0.0010, 0.010, 0.1]}\n",
        "     }\n",
        "}"
      ],
      "metadata": {
        "id": "xFhwvb7mTmOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_configuration, project=\"MLP-Obligatorio\", entity=\"vainilla\")\n",
        "wandb.agent(sweep_id, function=train_model_2, count=15, project='MLP-Obligatorio')"
      ],
      "metadata": {
        "id": "JupYfev2TnHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}