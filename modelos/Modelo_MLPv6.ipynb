{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#INSTALADORES"
      ],
      "metadata": {
        "id": "_kiCqVZRcZhm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4aDm5TNRY5eY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae4ea74-be5a-4807-9d75-da515fd51106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.4.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.22.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard\n",
        "!pip install torchinfo\n",
        "!pip install --upgrade torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "r9ok5rZZcgqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu3FLT0dTXk0",
        "outputId": "ad6770a9-7973-4865-d12e-a02b9b52cb29"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp \"/content/drive/MyDrive/Colab Notebooks/MLP/data.csv\" /content\n",
        "! cp \"/content/drive/MyDrive/Colab Notebooks/MLP/img.zip\" /content\n",
        "! unzip -q img.zip\n",
        "! rm img.zip"
      ],
      "metadata": {
        "id": "06svX9WspPhm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Weights and Biases INICIALIZACION"
      ],
      "metadata": {
        "id": "fOBI94ROcO25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login\n",
        "\n",
        "FALTA GENERAR EL PROYECTO MLP-Obligatorio  Y  OBTENER CLAVE\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "BVIaUD7HPXBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FUNCIONES BASE ENTRENO"
      ],
      "metadata": {
        "id": "0ApXh6VQc_tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchinfo\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import csv\n",
        "from PIL import Image\n",
        "\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "hPA9TFLZZoIh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_oneHot(label, numberOfClass):\n",
        "  oneHot_label = torch.zeros(label.shape[0],numberOfClass).to(device)\n",
        "  for i in range(label.shape[0]):\n",
        "    oneHot_label[i][label[i]]=1\n",
        "  return oneHot_label\n",
        "\n",
        "def train_step(mlp_model, criterion, optim, img,tabulars, label, batch_size, numberOfClass):\n",
        "    optim.zero_grad()\n",
        "    output = mlp_model(img, tabulars)\n",
        "    loss = criterion(output, label)\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "    step_loss = loss.item()\n",
        "    return step_loss\n",
        "\n",
        "def train_epoch(mlp_model, loader, criterion, optim,mb,numberOfClass):\n",
        "    epoch_loss_accumulated = 0.0\n",
        "    for img, tabulars, label in  progress_bar(loader,parent = mb):\n",
        "      batch_size = img.size(0)\n",
        "      epoch_loss_accumulated += train_step(mlp_model,criterion,optim, img, tabulars, label, batch_size,numberOfClass)\n",
        "    return epoch_loss_accumulated/len(loader)"
      ],
      "metadata": {
        "id": "eLuLVq3YA1rQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_epoch(mlp_model, val_loader, criterion, classes = None):\n",
        "    mlp_model.eval()\n",
        "    epoch_loss = 0.0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for images, tabulars, label in val_loader:\n",
        "        all_labels.extend(labels.numpy())  \n",
        "        labels = labels.to(device)\n",
        "        labels = to_oneHot(label,classes)\n",
        "        predictions = mlp_model(images.to(device), tabulars)\n",
        "        all_predictions.extend(torch.argmax(predictions, dim=1).cpu().numpy())\n",
        "\n",
        "        loss = criterion(predictions, labels)\n",
        "\n",
        "        epoch_loss += loss.item()    \n",
        "\n",
        "    return epoch_loss / len(val_loader), accuracy_score(all_labels, all_predictions) * 100"
      ],
      "metadata": {
        "id": "kjRB0qPKypTK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(mlp_model, train_loader, valid_loader, criterion, optim, number_epochs,numberOfClass):\n",
        "  train_history = []\n",
        "  valid_history = []\n",
        "  accuracy_history = []\n",
        "  now = datetime.datetime.now()\n",
        "  date_time = now.strftime(\"%m%d%Y_%H%M%S\")\n",
        "  name = 'runs/'+mlp_model.name+'_'+date_time\n",
        "  tensorBoard_writer = SummaryWriter(name) \n",
        "  mb = master_bar(range(1, number_epochs+1))\n",
        "  for epoch in mb:\n",
        "      start_time = time.time()     \n",
        "      train_loss = train_epoch(mlp_model, train_loader, criterion, optim,mb,numberOfClass)\n",
        "      train_history.append(train_loss)\n",
        "      print(\"Training epoch {} | Loss {:.6f} | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, train_loss, time.time() - start_time))\n",
        "      \n",
        "      start_time = time.time()\n",
        "      val_loss, acc = validation_epoch(mlp_model, valid_loader, criterion)\n",
        "      valid_history.append(val_loss)\n",
        "      accuracy_history.append(acc)\n",
        "      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, val_loss, acc, time.time() - start_time))\n",
        "      # Se carga en tensorBoard #Loss #Validation en train y val\n",
        "      tensorBoard_writer.add_scalar(tag=\"Train Loss\", scalar_value=train_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Loss\", scalar_value=val_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Accuracy\", scalar_value=acc, global_step=epoch)\n",
        "  tensorBoard_writer.close()"
      ],
      "metadata": {
        "id": "o2Q_Vlm0UYK7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CARGA DE DATOS"
      ],
      "metadata": {
        "id": "oNQ0ZMJFCxUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():  \n",
        "  data = []\n",
        "  with open(\"./data.csv\", 'r') as file:\n",
        "    lector_csv = csv.reader(file)\n",
        "    next(lector_csv)\n",
        "    for fila in lector_csv:\n",
        "      fila_enteros = [int(float(valor)) for valor in fila]\n",
        "      data.append(fila_enteros)\n",
        "\n",
        "  data = np.array(data)\n",
        "  nombres_imagenes = data[:, 0]\n",
        "\n",
        "  datos_con_imagenes = []\n",
        "\n",
        "  for nombre_imagen, fila_datos in zip(nombres_imagenes, data):\n",
        "      imagen = 0\n",
        "      try:\n",
        "        imagen = Image.open(\"./img/\" + str(nombre_imagen))\n",
        "        label = 0\n",
        "        if fila_datos[6] > 100000 and fila_datos[6] <= 200000:\n",
        "          label = 1\n",
        "        elif fila_datos[6] > 200000 and fila_datos[6] <= 300000:\n",
        "          label = 2\n",
        "        elif fila_datos[6] > 300000:\n",
        "          label = 3\n",
        "        datos_con_imagenes.append((np.array(imagen), fila_datos[1:6], label))\n",
        "      except FileNotFoundError:\n",
        "        print(\"Error: El archivo de imagen \" + str(nombre_imagen)+ \".jpeg no existe.\")\n",
        "      \n",
        "  print(len(datos_con_imagenes))\n",
        "  return datos_con_imagenes   "
      ],
      "metadata": {
        "id": "BH7li8FJv61n"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloaders(train_transf,batch_size):\n",
        "# Vector de vectores img, tabulares, label -------------------------------------------------------------------------------------------------------------------------------------\n",
        "  train_dataset = load_data()\n",
        "# Vector de vectores img, tabulares, label -------------------------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "  BATCH_SIZE = batch_size\n",
        "\n",
        "  # Separamos en train y validation\n",
        "  train_size = int(0.8 * len(train_dataset))\n",
        "  valid_size = len(train_dataset) - train_size\n",
        "\n",
        "  train, validation = torch.utils.data.random_split(train_dataset, [train_size,valid_size])\n",
        "\n",
        "  print(f\"{len(train)} Training Items, {len(validation)} Validation Items\")\n",
        "\n",
        "  # Podemos usar data loaders como vimos en el pr√°ctico.\n",
        "  train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True,pin_memory=True)\n",
        "  valid_loader = DataLoader(validation, batch_size=BATCH_SIZE, pin_memory=True)\n",
        "  \n",
        "  return train_loader, valid_loader"
      ],
      "metadata": {
        "id": "jqO-VeKccgRg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODELO"
      ],
      "metadata": {
        "id": "-Ww-iF4vDILl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "DTVLeMkfHqji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d44668-25d4-421e-cbad-39617e16c376"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_Model(nn.Module):\n",
        "  def __init__(self,name=\"MLP_MODEL\", vocab_size=260, embedding_dim=4, num_classes=4):\n",
        "    super().__init__()\n",
        "    self.name = name\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size,embedding_dim=embedding_dim)\n",
        "    self.conv1 = nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(256)\n",
        "    self.conv4 = nn.Conv2d(256, 64, 4, stride=2, padding=1, bias=False)\n",
        "    self.bn4 = nn.BatchNorm2d(64)\n",
        "    self.linear1 = nn.Linear(64*16*12+5+(embedding_dim-1), 1024)\n",
        "    self.linear2 = nn.Linear(1024, 512)\n",
        "    self.linear3 = nn.Linear(512, 128)\n",
        "    self.linear4 = nn.Linear(128, 64)\n",
        "    self.out = nn.Linear(64, num_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x,tabulars):\n",
        "    # entrada de 256*192\n",
        "    emb_Location = self.embedding(tabulars[4])\n",
        "    x = x.view(x.size(0), 3, 256, 192)\n",
        "    x = F.relu(self.bn1(self.conv1(x)))\n",
        "    x = F.relu(self.bn2(self.conv2(x)))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    x = F.relu(self.bn4(self.conv4(x)))\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = torch.concat([x, tabulars[0:4], emb_Location], -1)\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = F.relu(self.linear2(x))\n",
        "    x = F.relu(self.linear3(x))\n",
        "    x = F.relu(self.linear4(x))\n",
        "    return x"
      ],
      "metadata": {
        "id": "Vjr6zGNfWcwb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchinfo.summary(MLP_Model())"
      ],
      "metadata": {
        "id": "hp9pNKPObREb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PARAMETROS"
      ],
      "metadata": {
        "id": "46EeU_3DDUav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = wandb.config # Config is a variable that holds and saves hyperparameters and inputs\n",
        "\n",
        "config.LR = 2e-4\n",
        "config.epochs = 50\n",
        "config.batch_size = 32\n",
        "config.B = [0.5,0.999]\n",
        "config.info = 'Modelo MLP'"
      ],
      "metadata": {
        "id": "J3Ru6ebWQ0JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos los dataloaders\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize([256,192]),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Creamos el loaders\n",
        "train_loader, val_loader = get_dataloaders(train_transform,batch_size=32)"
      ],
      "metadata": {
        "id": "fLVRgXZ9wZNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01574e2-32d6-45c1-b3c5-0d4f882ba4c3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: El archivo de imagen 1787.jpeg no existe.\n",
            "Error: El archivo de imagen 1942.jpeg no existe.\n",
            "Error: El archivo de imagen 3140.jpeg no existe.\n",
            "Error: El archivo de imagen 3280.jpeg no existe.\n",
            "Error: El archivo de imagen 3297.jpeg no existe.\n",
            "Error: El archivo de imagen 3308.jpeg no existe.\n",
            "Error: El archivo de imagen 3667.jpeg no existe.\n",
            "Error: El archivo de imagen 3720.jpeg no existe.\n",
            "Error: El archivo de imagen 3784.jpeg no existe.\n",
            "Error: El archivo de imagen 4348.jpeg no existe.\n",
            "Error: El archivo de imagen 4621.jpeg no existe.\n",
            "Error: El archivo de imagen 5423.jpeg no existe.\n",
            "Error: El archivo de imagen 5492.jpeg no existe.\n",
            "Error: El archivo de imagen 5900.jpeg no existe.\n",
            "Error: El archivo de imagen 5918.jpeg no existe.\n",
            "Error: El archivo de imagen 6018.jpeg no existe.\n",
            "Error: El archivo de imagen 6071.jpeg no existe.\n",
            "Error: El archivo de imagen 7318.jpeg no existe.\n",
            "Error: El archivo de imagen 7701.jpeg no existe.\n",
            "Error: El archivo de imagen 7769.jpeg no existe.\n",
            "Error: El archivo de imagen 8312.jpeg no existe.\n",
            "Error: El archivo de imagen 8501.jpeg no existe.\n",
            "Error: El archivo de imagen 8650.jpeg no existe.\n",
            "Error: El archivo de imagen 8788.jpeg no existe.\n",
            "Error: El archivo de imagen 8821.jpeg no existe.\n",
            "Error: El archivo de imagen 8917.jpeg no existe.\n",
            "Error: El archivo de imagen 9450.jpeg no existe.\n",
            "Error: El archivo de imagen 10340.jpeg no existe.\n",
            "Error: El archivo de imagen 11178.jpeg no existe.\n",
            "Error: El archivo de imagen 11243.jpeg no existe.\n",
            "Error: El archivo de imagen 11614.jpeg no existe.\n",
            "Error: El archivo de imagen 11781.jpeg no existe.\n",
            "Error: El archivo de imagen 11830.jpeg no existe.\n",
            "Error: El archivo de imagen 13931.jpeg no existe.\n",
            "Error: El archivo de imagen 14094.jpeg no existe.\n",
            "Error: El archivo de imagen 14524.jpeg no existe.\n",
            "Error: El archivo de imagen 14706.jpeg no existe.\n",
            "Error: El archivo de imagen 15320.jpeg no existe.\n",
            "Error: El archivo de imagen 15814.jpeg no existe.\n",
            "Error: El archivo de imagen 16742.jpeg no existe.\n",
            "Error: El archivo de imagen 16747.jpeg no existe.\n",
            "Error: El archivo de imagen 16887.jpeg no existe.\n",
            "Error: El archivo de imagen 16918.jpeg no existe.\n",
            "Error: El archivo de imagen 16935.jpeg no existe.\n",
            "Error: El archivo de imagen 17097.jpeg no existe.\n",
            "Error: El archivo de imagen 17441.jpeg no existe.\n",
            "Error: El archivo de imagen 18949.jpeg no existe.\n",
            "Error: El archivo de imagen 19216.jpeg no existe.\n",
            "Error: El archivo de imagen 19638.jpeg no existe.\n",
            "Error: El archivo de imagen 19959.jpeg no existe.\n",
            "Error: El archivo de imagen 20058.jpeg no existe.\n",
            "Error: El archivo de imagen 20129.jpeg no existe.\n",
            "Error: El archivo de imagen 20159.jpeg no existe.\n",
            "Error: El archivo de imagen 20544.jpeg no existe.\n",
            "Error: El archivo de imagen 20679.jpeg no existe.\n",
            "Error: El archivo de imagen 21108.jpeg no existe.\n",
            "Error: El archivo de imagen 22079.jpeg no existe.\n",
            "Error: El archivo de imagen 22244.jpeg no existe.\n",
            "Error: El archivo de imagen 22272.jpeg no existe.\n",
            "Error: El archivo de imagen 22619.jpeg no existe.\n",
            "Error: El archivo de imagen 22830.jpeg no existe.\n",
            "Error: El archivo de imagen 23190.jpeg no existe.\n",
            "Error: El archivo de imagen 23277.jpeg no existe.\n",
            "Error: El archivo de imagen 23575.jpeg no existe.\n",
            "Error: El archivo de imagen 24091.jpeg no existe.\n",
            "Error: El archivo de imagen 24735.jpeg no existe.\n",
            "Error: El archivo de imagen 25128.jpeg no existe.\n",
            "Error: El archivo de imagen 25761.jpeg no existe.\n",
            "Error: El archivo de imagen 26000.jpeg no existe.\n",
            "Error: El archivo de imagen 26248.jpeg no existe.\n",
            "Error: El archivo de imagen 26743.jpeg no existe.\n",
            "Error: El archivo de imagen 26854.jpeg no existe.\n",
            "Error: El archivo de imagen 27635.jpeg no existe.\n",
            "Error: El archivo de imagen 29371.jpeg no existe.\n",
            "Error: El archivo de imagen 29473.jpeg no existe.\n",
            "Error: El archivo de imagen 29820.jpeg no existe.\n",
            "Error: El archivo de imagen 30147.jpeg no existe.\n",
            "Error: El archivo de imagen 30532.jpeg no existe.\n",
            "Error: El archivo de imagen 31241.jpeg no existe.\n",
            "Error: El archivo de imagen 31854.jpeg no existe.\n",
            "Error: El archivo de imagen 32065.jpeg no existe.\n",
            "Error: El archivo de imagen 32458.jpeg no existe.\n",
            "Error: El archivo de imagen 32876.jpeg no existe.\n",
            "Error: El archivo de imagen 33089.jpeg no existe.\n",
            "Error: El archivo de imagen 33363.jpeg no existe.\n",
            "Error: El archivo de imagen 34188.jpeg no existe.\n",
            "Error: El archivo de imagen 34281.jpeg no existe.\n",
            "Error: El archivo de imagen 34785.jpeg no existe.\n",
            "Error: El archivo de imagen 34856.jpeg no existe.\n",
            "Error: El archivo de imagen 35378.jpeg no existe.\n",
            "Error: El archivo de imagen 36769.jpeg no existe.\n",
            "Error: El archivo de imagen 36801.jpeg no existe.\n",
            "Error: El archivo de imagen 37702.jpeg no existe.\n",
            "Error: El archivo de imagen 38168.jpeg no existe.\n",
            "Error: El archivo de imagen 38855.jpeg no existe.\n",
            "Error: El archivo de imagen 38990.jpeg no existe.\n",
            "Error: El archivo de imagen 39594.jpeg no existe.\n",
            "Error: El archivo de imagen 39843.jpeg no existe.\n",
            "Error: El archivo de imagen 39944.jpeg no existe.\n",
            "Error: El archivo de imagen 39996.jpeg no existe.\n",
            "Error: El archivo de imagen 40099.jpeg no existe.\n",
            "Error: El archivo de imagen 41026.jpeg no existe.\n",
            "Error: El archivo de imagen 41087.jpeg no existe.\n",
            "Error: El archivo de imagen 41630.jpeg no existe.\n",
            "Error: El archivo de imagen 42443.jpeg no existe.\n",
            "Error: El archivo de imagen 42977.jpeg no existe.\n",
            "Error: El archivo de imagen 43082.jpeg no existe.\n",
            "Error: El archivo de imagen 43177.jpeg no existe.\n",
            "Error: El archivo de imagen 43580.jpeg no existe.\n",
            "Error: El archivo de imagen 43795.jpeg no existe.\n",
            "Error: El archivo de imagen 44808.jpeg no existe.\n",
            "Error: El archivo de imagen 44923.jpeg no existe.\n",
            "Error: El archivo de imagen 44990.jpeg no existe.\n",
            "Error: El archivo de imagen 45613.jpeg no existe.\n",
            "Error: El archivo de imagen 45764.jpeg no existe.\n",
            "Error: El archivo de imagen 47459.jpeg no existe.\n",
            "Error: El archivo de imagen 47462.jpeg no existe.\n",
            "Error: El archivo de imagen 47759.jpeg no existe.\n",
            "Error: El archivo de imagen 48103.jpeg no existe.\n",
            "Error: El archivo de imagen 48289.jpeg no existe.\n",
            "Error: El archivo de imagen 48517.jpeg no existe.\n",
            "Error: El archivo de imagen 48870.jpeg no existe.\n",
            "24977\n",
            "19981 Training Items, 4996 Validation Items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ENTRENAMIENTO"
      ],
      "metadata": {
        "id": "joJAzx9jDY5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos el modelo y el optimizador\n",
        "LR = 2e-4\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "B = [0.5,0.999]\n",
        "mlp_model = MLP_Model(\"MLP MODEL\", vocab_size=260, embedding_dim=4, num_classes=4).to(device)\n",
        "opt = torch.optim.Adam(mlp_model.parameters(), lr=LR,betas=B)\n",
        "crit = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "3GeuvA4gYlnh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(mlp_model, train_loader, val_loader, crit, opt, epochs, 4)"
      ],
      "metadata": {
        "id": "1qMpWzA5_lSx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95c05c31-5f1c-494b-d69d-1a89b12e1924"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='0' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/50 00:00&lt;?]\n",
              "    </div>\n",
              "    \n",
              "\n",
              "\n",
              "    <div>\n",
              "      <progress value='0' class='' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/625 00:00&lt;?]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-c4a0982d054f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-30f8e768413c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(mlp_model, train_loader, valid_loader, criterion, optim, number_epochs, numberOfClass)\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberOfClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       print(\"Training epoch {} | Loss {:.6f} | Time {:.2f} seconds\"\n",
            "\u001b[0;32m<ipython-input-25-8626baec9283>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(mlp_model, loader, criterion, optim, mb, numberOfClass)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabulars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m       \u001b[0mepoch_loss_accumulated\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabulars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberOfClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_loss_accumulated\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-8626baec9283>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(mlp_model, criterion, optim, img, tabulars, label, batch_size, numberOfClass)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtabulars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumberOfClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtabulars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-4d015dd082f0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, tabulars)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0memb_Location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtabulars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Byte but found Float"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardado del modelo\n",
        "\n",
        "torch.save(mlp_model.state_dict(),mlp_model.name+\".dat\")"
      ],
      "metadata": {
        "id": "sU3RPUbglQaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=runs/"
      ],
      "metadata": {
        "id": "tWTpshes5wYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Weights and Biases IMPLEMENTACION"
      ],
      "metadata": {
        "id": "FqJQhl6pVmlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_2():\n",
        "  \n",
        "  train_loader, val_loader, num_classes = get_dataloaders(train_transform,config.batch_size)\n",
        "  mlp_model = MLP_Model(\"MLP MODEL\", vocab_size=200, embedding_dim=4, num_classes=4).to(device)\n",
        "  opt = torch.optim.Adam(mlp_model.parameters(), lr=config.LR,betas=config.B)\n",
        "  crit = nn.CrossEntropyLoss()\n",
        "  \n",
        "  train_history = []\n",
        "  valid_history = []\n",
        "  accuracy_history = []\n",
        "  now = datetime.datetime.now()\n",
        "  date_time = now.strftime(\"%m%d%Y_%H%M%S\")\n",
        "  name = 'runs/'+mlp_model.name+'_'+date_time\n",
        "  tensorBoard_writer = SummaryWriter(name) \n",
        "  mb = master_bar(range(1, config.epochs+1))\n",
        "  for epoch in mb:\n",
        "      start_time = time.time()     \n",
        "      train_loss = train_epoch(mlp_model, train_loader, crit, opt,mb,num_classes)\n",
        "      train_history.append(train_loss)\n",
        "      print(\"Training epoch {} | Loss {:.6f} | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, train_loss, time.time() - start_time))\n",
        "      \n",
        "      start_time = time.time()\n",
        "      val_loss, acc = validation_epoch(mlp_model, val_loader, crit)\n",
        "      valid_history.append(val_loss)\n",
        "      accuracy_history.append(acc)\n",
        "      print(\"Validation epoch {} | Loss {:.6f} | Accuracy {:.2f}% | Time {:.2f} seconds\"\n",
        "            .format(epoch + 1, val_loss, acc, time.time() - start_time))\n",
        "      # Se carga en tensorBoard #Loss #Validation en train y val\n",
        "      tensorBoard_writer.add_scalar(tag=\"Train Loss\", scalar_value=train_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Loss\", scalar_value=val_loss, global_step=epoch)\n",
        "      tensorBoard_writer.add_scalar(tag=\"Validation Accuracy\", scalar_value=acc, global_step=epoch)\n",
        "  tensorBoard_writer.close()"
      ],
      "metadata": {
        "id": "RLWEN2JwXC1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_configuration = {\n",
        "    'method': 'grid',         # 'grid', 'hyperopt', 'bayesian'\n",
        "    'metric': {\n",
        "        'name': 'acc',     # 'accuracy'\n",
        "        'goal': 'maximize'      # 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'batch_size': {'values': [32]},\n",
        "        'epochs': {'values': [5,10,20,50,100]},\n",
        "        'B': {'values': [[0.5,0.999]]},\n",
        "        'learning_rate': {'values': [0.0002, 0.0004, 0.0006, 0.0010, 0.010, 0.1]}\n",
        "     }\n",
        "}"
      ],
      "metadata": {
        "id": "xFhwvb7mTmOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_configuration, project=\"MLP-Obligatorio\", entity=\"vainilla\")\n",
        "wandb.agent(sweep_id, function=train_model_2, count=15, project='MLP-Obligatorio')"
      ],
      "metadata": {
        "id": "JupYfev2TnHZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}